{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858737f3",
   "metadata": {},
   "source": [
    "This notebook applies the fully-trained model to a test set of film chips. The tile_scan function contains the labelling logic and saves the results as a json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a68f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from statistics import mode\n",
    "from statistics import mean\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5626ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "checkpoint_path = # path to the final trained model\n",
    "\n",
    "# process path\n",
    "process_path = # path to the test film chips\n",
    "\n",
    "# set the confidence threshold for the network\n",
    "threshold = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7625320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d2f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to convert 8bit arrays to 1bit arrays that the network can understand\n",
    "def eight_to_one(crop):\n",
    "    \n",
    "    # scale each array to be between 0 and 1\n",
    "    array = crop/255\n",
    "    \n",
    "    # reshape it, network expects <samples, x_dimension, y_dimension, bands>\n",
    "    array = np.expand_dims(array, axis=2)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948b92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a slightly different function to do the tiling, note the log_tiles flag\n",
    "def tile_scan(source_path, desired_samples_per_image, desired_tile_dimension, log_tiles):\n",
    "\n",
    "    # get start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # make a dict to store overall results\n",
    "    results = {}\n",
    "\n",
    "    # get a list of scans to process\n",
    "    images_to_process = glob.glob(process_path + '*.TIFF')\n",
    "\n",
    "    # loop through all the images\n",
    "    for image in images_to_process:\n",
    "\n",
    "        # get the image name (adjust if filetype changes, PLEASE READ THIS TIM)\n",
    "        image_name = image[len(source_path):-5]\n",
    "        \n",
    "        # set the tile save path\n",
    "        tile_path = os.path.join(process_path, image_name)\n",
    "        \n",
    "        # print name\n",
    "        print('Processing:', image_name)\n",
    "        \n",
    "        # check if tiles are to be saved\n",
    "        if log_tiles == True:\n",
    "            \n",
    "            # don't create a new directory if it exists\n",
    "            if not os.path.exists(os.path.join(process_path, image_name)):\n",
    "                \n",
    "                # create a subfolder to save tiles\n",
    "                os.mkdir(tile_path)\n",
    "\n",
    "        # open the file\n",
    "        img = Image.open(image)\n",
    "\n",
    "        # get the dimensions of the image\n",
    "        imageWidth, imageHeight = img.size\n",
    "        \n",
    "        # get the number of pixels per tile\n",
    "        pixel_count = desired_tile_dimension*desired_tile_dimension\n",
    "\n",
    "        # sets the x and y ranges \n",
    "        rangex = math.ceil(imageWidth / desired_tile_dimension)\n",
    "        rangey = math.ceil(imageHeight / desired_tile_dimension)\n",
    "        total_frames = rangex * rangey\n",
    "        \n",
    "        # make a counter to count samples attempted and successful\n",
    "        number_of_samples = 0\n",
    "        attempted_samples = 0\n",
    "        \n",
    "        # make a list to store scan results\n",
    "        sample_list = []\n",
    "        \n",
    "        # tile sample tuples\n",
    "        tile_tuples = []\n",
    "        \n",
    "        # only generate the minimum samples\n",
    "        while number_of_samples < desired_samples_per_image and attempted_samples < 250: \n",
    "\n",
    "            # get random x and y coordinates to sample, stay away from the edges of the scan\n",
    "            rand_x = np.random.randint(2, rangex-2)\n",
    "            rand_y = np.random.randint(6, rangey-3)\n",
    "            \n",
    "            # generate a coordinate tuple\n",
    "            tile_tuple = (rand_x, rand_y)\n",
    "            \n",
    "            # if the tile is unqiue, process it\n",
    "            if tile_tuple not in tile_tuples:\n",
    "                \n",
    "                # note a new attempt\n",
    "                attempted_samples += 1\n",
    "                \n",
    "                # mark that tile as processed\n",
    "                tile_tuples.append(tile_tuple)\n",
    "\n",
    "                # set the crop coordinates. box = (<start x>, <start y>, <end x>, <end y>)\n",
    "                box = (rand_x*desired_tile_dimension, \n",
    "                       rand_y*desired_tile_dimension, \n",
    "                       rand_x*desired_tile_dimension+desired_tile_dimension, \n",
    "                       rand_y*desired_tile_dimension+desired_tile_dimension)\n",
    "\n",
    "                # crop each tile\n",
    "                tile = img.crop(box)\n",
    "\n",
    "                # get the image as an array\n",
    "                tile_array = np.asarray(tile)\n",
    "\n",
    "                # convert to binary\n",
    "                ret, binary_tile8 = cv2.threshold(tile_array, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                # format the crop for network processing\n",
    "                binary_tile = eight_to_one(binary_tile8)\n",
    "\n",
    "                # ignore mostly white images. We want between 50% and 95% white\n",
    "                if np.sum(binary_tile) < 0.95*pixel_count and np.sum(binary_tile) > 0.5*pixel_count:\n",
    "                    \n",
    "                    # get the classification, the network expects a list\n",
    "                    prediction = model.predict(binary_tile)\n",
    "\n",
    "                    # check that the tile exceeds our confidence threshold\n",
    "                    if np.max(prediction) > threshold:\n",
    "\n",
    "                        # note successful sample\n",
    "                        number_of_samples += 1\n",
    "\n",
    "                        # convert the one-hot encoding to the actual class labels\n",
    "                        label = np.where(prediction == np.max(prediction))[1][0]\n",
    "\n",
    "                        # save the prediction and confidence to the results list\n",
    "                        results_dict = {'x': int(rand_x),\n",
    "                                        'y': int(rand_y), \n",
    "                                        'class_label': int(label),\n",
    "                                        'confidence': float(np.max(prediction))}\n",
    "\n",
    "                        # add the sample data to the sample list\n",
    "                        sample_list.append(results_dict)\n",
    "\n",
    "                        # check if tiles are to be saved\n",
    "                        if log_tiles == True:\n",
    "\n",
    "                            # set the tile save name\n",
    "                            padding_x_zeros = len(str(rangex))\n",
    "                            padding_y_zeros = len(str(rangey))\n",
    "                            filename = '{}_{}_{}-{}.png'.format(image_name, \n",
    "                                                                str(rand_y).zfill(padding_y_zeros), \n",
    "                                                                str(rand_x).zfill(padding_x_zeros),\n",
    "                                                                str(label))\n",
    "                            # save the tile\n",
    "                            Image.fromarray(binary_tile8).save(os.path.join(tile_path, filename))\n",
    "\n",
    "                # note another sample\n",
    "                else:\n",
    "                    attempted_samples += 1\n",
    "                \n",
    "                # add to the overall data dict\n",
    "                results[image_name] = sample_list\n",
    "\n",
    "        # clear the output \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "    # save  to a log\n",
    "    with open(process_path + 'tile_classification_results.json', 'a') as outfile:\n",
    "        outfile.write(json.dumps(results)) \n",
    "        \n",
    "    # get end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('Processing time: {:.3}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fddbc547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 3.36e+02s\n"
     ]
    }
   ],
   "source": [
    "tile_scan(process_path, 200, 200, log_tiles=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cf68d",
   "metadata": {},
   "source": [
    "Took 455s for 74 scans each with 100 samples. ~6s per scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e995e",
   "metadata": {},
   "source": [
    "# Classify each scan\n",
    "\n",
    "This section loads the previous output, and applies the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a8ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "process_path = r'E:/USGS/test/'\n",
    "\n",
    "# json log path\n",
    "json_path = process_path + 'tile_classification_results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464b70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json\n",
    "with open(json_path, 'r') as data:\n",
    "     json_data = json.loads(data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "148b206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the image dictionary\n",
    "for key in json_data.keys():\n",
    "    \n",
    "    # set up a list to store class labels for each scan\n",
    "    class_label_list = []\n",
    "    \n",
    "    # get the image name\n",
    "    name = key\n",
    "    \n",
    "    # get the predictions\n",
    "    prediction_list = json_data[key]\n",
    "    \n",
    "    # loop through the predictions\n",
    "    for predict_index in range(0, len(prediction_list)):\n",
    "        \n",
    "        # get the class\n",
    "        classification = prediction_list[predict_index]['class_label']\n",
    "        \n",
    "        # add it to the list\n",
    "        class_label_list.append(classification)\n",
    "    \n",
    "    # check for guesses\n",
    "    if len(class_label_list) != 0:\n",
    "    \n",
    "        # get some basic statistics \n",
    "        scan_mean = mean(class_label_list)\n",
    "        scan_mode = mode(class_label_list)\n",
    "        scan_max = max(class_label_list)\n",
    "\n",
    "        # apply logic to get an overall label for each scan, this can and should be modified\n",
    "        if scan_max == 0:\n",
    "            label = '0' # no interest\n",
    "\n",
    "        elif scan_max == 1:\n",
    "            label = '1' # little interest\n",
    "\n",
    "        elif scan_max == 2 and scan_mode ==2:\n",
    "            label = '3' # high interest\n",
    "            \n",
    "        elif scan_max == 2 and scan_mean < 1.5:\n",
    "            label = '2' # interest\n",
    "            \n",
    "        elif scan_max == 2 and scan_mean > 1.5:\n",
    "            label = '3' # high interest\n",
    "            \n",
    "    # add an error label\n",
    "    else:\n",
    "        label = 'ERROR: could not determine'\n",
    "        \n",
    "    # save the results to a log\n",
    "    with open(process_path + 'scan_classification_results.csv', 'a') as outfile:\n",
    "        outfile.write('{}, {}, {}, {}, {}\\n'.format(name, scan_mean, scan_mode, scan_max, label)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
